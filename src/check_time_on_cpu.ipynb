{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\imars\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2idx = {'O': 0, 'B-discount': 1, 'B-value': 2, 'I-value': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\imars\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = 'ai-forever/ruElectra-small'\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels = len(label2idx)).to('cpu')\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data_with_entity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_prepare_inputs(texts):\n",
    "    tokenized_inputs = tokenizer(texts, truncation=True, is_split_into_words=True, return_tensors=\"pt\", padding=True, max_length=512)\n",
    "    return tokenized_inputs.to('cpu')\n",
    "\n",
    "# Функция для получения предсказаний\n",
    "def predict(texts):\n",
    "    model.eval()\n",
    "    inputs = tokenize_and_prepare_inputs(texts)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    predictions = torch.argmax(outputs.logits, dim=2)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenize_and_prepare_inputs(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "mean_time = []\n",
    "for i in range(30):\n",
    "    v_data = [' '.join(data['sent'].sample().to_list()) for i in range(25)]\n",
    "    sent = [i.split() for i in v_data]\n",
    "    start_time = time.time()\n",
    "    pred = predict(sent)\n",
    "    end_time = time.time()\n",
    "    mean_time.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее время работы:  9.194216442108154 среднее квадратичное отклонение:  4.750438888324384\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('Среднее время работы: ',np.mean(mean_time), 'среднее квадратичное отклонение: ', np.std(mean_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "from onnxruntime import (\n",
    "    InferenceSession,\n",
    "    SessionOptions\n",
    ")\n",
    "\n",
    "\n",
    "def create_onnx_session(\n",
    "        model_path: str,\n",
    "        provider: str = \"CPUExecutionProvider\"\n",
    ") -> InferenceSession:\n",
    "    \"\"\"Создание сессии для инференса модели с помощью ONNX Runtime.\n",
    "\n",
    "    @param model_path: путь к модели в формате ONNX\n",
    "    @param provider: инференс на ЦП\n",
    "    @return: ONNX Runtime-сессия\n",
    "    \"\"\"    \n",
    "    options = SessionOptions()\n",
    "    options.graph_optimization_level = \\\n",
    "        onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "    options.intra_op_num_threads = 1\n",
    "    session = InferenceSession(model_path, options, providers=[provider])\n",
    "    session.disable_fallback()\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = create_onnx_session('ruElectra-small-onnx-quantized.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from onnxruntime import InferenceSession\n",
    "\n",
    "\n",
    "def onnx_inference(\n",
    "        text: list,\n",
    "        session: InferenceSession,\n",
    "        tokenizer: AutoTokenizer,\n",
    "        max_length: int\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Инференс модели с помощью ONNX Runtime.\n",
    "\n",
    "    @param text: входной текст для классификации\n",
    "    @param session: ONNX Runtime-сессия\n",
    "    @param tokenizer: токенизатор\n",
    "    @param max_length: максимальная длина последовательности в токенах\n",
    "    @return: логиты на выходе из модели\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"np\",\n",
    "    )\n",
    "    input_feed = {\n",
    "        \"input_ids\": inputs[\"input_ids\"].astype(np.int64)\n",
    "    }\n",
    "    outputs = session.run(\n",
    "        output_names=[\"output\"],\n",
    "        input_feed=input_feed\n",
    "    )[0]\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "mean_time_onnx = []\n",
    "for i in range(30):\n",
    "    v_data = [' '.join(data['sent'].sample().to_list()) for i in range(25)]\n",
    "    sent = [i.split() for i in v_data]\n",
    "    start_time = time.time()\n",
    "    pred = onnx_inference(v_data, session, tokenizer, 512)\n",
    "    end_time = time.time()\n",
    "    mean_time_onnx.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 1, 1,  ..., 1, 1, 1],\n",
       "        [3, 1, 1,  ..., 1, 1, 1],\n",
       "        [3, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [3, 1, 1,  ..., 1, 1, 1],\n",
       "        [3, 1, 1,  ..., 1, 1, 1],\n",
       "        [3, 1, 1,  ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(torch.Tensor(pred), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее время работы:  3.8348785161972048 среднее квадратичное отклонение:  0.722076557095312\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('Среднее время работы: ',np.mean(mean_time_onnx), 'среднее квадратичное отклонение: ', np.std(mean_time_onnx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
